{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced OpenAI Agents with Tools\n",
        "\n",
        "This notebook demonstrates more advanced usage of OpenAI Agents with custom tools and multi-agent workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the required packages and set up our environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# %pip install openai python-dotenv requests pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from typing import Dict, List, Optional, Any, Union\n",
        "from pydantic import BaseModel, Field\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "print(\"Environment initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Creating Structured Tools\n",
        "\n",
        "Let's define some custom tools with proper schema definitions using Pydantic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define tool schemas\n",
        "class SearchQuery(BaseModel):\n",
        "    \"\"\"Search query parameters\"\"\"\n",
        "    query: str = Field(..., description=\"The search query string\")\n",
        "    max_results: int = Field(5, description=\"Maximum number of results to return\")\n",
        "\n",
        "class WeatherRequest(BaseModel):\n",
        "    \"\"\"Weather request parameters\"\"\"\n",
        "    location: str = Field(..., description=\"City name or location\")\n",
        "    units: str = Field(\"metric\", description=\"Units: 'metric' for Celsius, 'imperial' for Fahrenheit\")\n",
        "    \n",
        "class TextAnalysisRequest(BaseModel):\n",
        "    \"\"\"Text analysis parameters\"\"\"\n",
        "    text: str = Field(..., description=\"The text to analyze\")\n",
        "    analysis_type: str = Field(..., description=\"Type of analysis: 'sentiment', 'entities', or 'summary'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement tool functions\n",
        "def search_web(params: Dict[str, Any]) -> str:\n",
        "    \"\"\"Mock web search function\"\"\"\n",
        "    query = params.get(\"query\", \"\")\n",
        "    max_results = params.get(\"max_results\", 5)\n",
        "    \n",
        "    # In a real implementation, this would call a search API\n",
        "    results = [\n",
        "        {\"title\": f\"Result {i} for {query}\", \"snippet\": f\"This is a snippet for result {i}\"}\n",
        "        for i in range(1, min(max_results + 1, 6))\n",
        "    ]\n",
        "    \n",
        "    return json.dumps(results, indent=2)\n",
        "\n",
        "def get_weather(params: Dict[str, Any]) -> str:\n",
        "    \"\"\"Mock weather information function\"\"\"\n",
        "    location = params.get(\"location\", \"\")\n",
        "    units = params.get(\"units\", \"metric\")\n",
        "    \n",
        "    temp = 22 if units == \"metric\" else 72\n",
        "    unit_symbol = \"°C\" if units == \"metric\" else \"°F\"\n",
        "    \n",
        "    # In a real implementation, this would call a weather API\n",
        "    weather_data = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": f\"{temp}{unit_symbol}\",\n",
        "        \"conditions\": \"Partly cloudy\",\n",
        "        \"humidity\": \"65%\",\n",
        "        \"wind\": \"10 km/h\"\n",
        "    }\n",
        "    \n",
        "    return json.dumps(weather_data, indent=2)\n",
        "\n",
        "def analyze_text(params: Dict[str, Any]) -> str:\n",
        "    \"\"\"Mock text analysis function\"\"\"\n",
        "    text = params.get(\"text\", \"\")\n",
        "    analysis_type = params.get(\"analysis_type\", \"sentiment\")\n",
        "    \n",
        "    if analysis_type == \"sentiment\":\n",
        "        # In a real implementation, this would use NLP\n",
        "        return json.dumps({\"sentiment\": \"positive\", \"confidence\": 0.85})\n",
        "    elif analysis_type == \"entities\":\n",
        "        # Extract random entities as example\n",
        "        words = text.split()\n",
        "        entities = [words[i] for i in range(0, len(words), 3) if i < len(words)]\n",
        "        return json.dumps({\"entities\": entities})\n",
        "    elif analysis_type == \"summary\":\n",
        "        # Create a mock summary\n",
        "        return json.dumps({\"summary\": f\"Summary of: {text[:50]}...\"})\n",
        "    else:\n",
        "        return json.dumps({\"error\": \"Invalid analysis type\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the tools in OpenAI's format\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"search_web\",\n",
        "            \"description\": \"Search the web for information on a given topic\",\n",
        "            \"parameters\": SearchQuery.schema()\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get current weather information for a location\",\n",
        "            \"parameters\": WeatherRequest.schema()\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"analyze_text\",\n",
        "            \"description\": \"Analyze text for sentiment, entities, or generate a summary\",\n",
        "            \"parameters\": TextAnalysisRequest.schema()\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Advanced Agent with Multiple Tools\n",
        "\n",
        "Now let's create an advanced agent that can use multiple tools efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_advanced_agent(user_query):\n",
        "    \"\"\"Run an advanced agent with access to multiple tools\"\"\"\n",
        "    # Initial system message defines agent capabilities and behavior\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"\n",
        "            You are an advanced AI assistant with access to multiple tools.\n",
        "            You can search the web, check weather, and analyze text.\n",
        "            Use these tools to provide comprehensive, accurate answers.\n",
        "            When using multiple tools, organize your responses clearly.\n",
        "            Always cite your sources when providing factual information.\n",
        "            \"\"\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": user_query}\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\nProcessing query: {user_query}\")\n",
        "    print(\"\\nThinking...\")\n",
        "    \n",
        "    # We'll allow multiple tool call cycles for complex tasks\n",
        "    max_turns = 3\n",
        "    current_turn = 0\n",
        "    \n",
        "    while current_turn < max_turns:\n",
        "        current_turn += 1\n",
        "        \n",
        "        # Get assistant's response with potential tool calls\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",  # Using GPT-4o for advanced capabilities\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            tool_choice=\"auto\"\n",
        "        )\n",
        "        \n",
        "        assistant_response = response.choices[0].message\n",
        "        messages.append(assistant_response)\n",
        "        \n",
        "        # If no tool calls or final response, we're done\n",
        "        if not assistant_response.tool_calls:\n",
        "            print(f\"\\nFinal Response (after {current_turn} turns):\")\n",
        "            print(assistant_response.content)\n",
        "            break\n",
        "            \n",
        "        # Process tool calls\n",
        "        print(f\"\\nTurn {current_turn}: Processing {len(assistant_response.tool_calls)} tool calls...\")\n",
        "        \n",
        "        for tool_call in assistant_response.tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            \n",
        "            print(f\"  - Executing {function_name} with args: {function_args}\")\n",
        "            \n",
        "            # Call the appropriate function\n",
        "            if function_name == \"search_web\":\n",
        "                function_response = search_web(function_args)\n",
        "            elif function_name == \"get_weather\":\n",
        "                function_response = get_weather(function_args)\n",
        "            elif function_name == \"analyze_text\":\n",
        "                function_response = analyze_text(function_args)\n",
        "            else:\n",
        "                function_response = json.dumps({\"error\": f\"Unknown function {function_name}\"})\n",
        "            \n",
        "            # Add tool response to messages\n",
        "            messages.append({\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response\n",
        "            })\n",
        "    \n",
        "    # Get final response if we exited due to max turns\n",
        "    if current_turn == max_turns and assistant_response.tool_calls:\n",
        "        final_response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=messages\n",
        "        )\n",
        "        \n",
        "        print(f\"\\nFinal Response (after maximum {max_turns} turns):\")\n",
        "        print(final_response.choices[0].message.content)\n",
        "    \n",
        "    return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with a complex query that may require multiple tools\n",
        "complex_query = \"What's the weather in Tokyo right now, and can you find information about popular tourist attractions there? Also, analyze the sentiment of this review: 'The hotel was amazing with great views, but the staff was somewhat unfriendly.'\"\n",
        "\n",
        "# Run the agent\n",
        "conversation = run_advanced_agent(complex_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Specialized Agent for Data Analysis\n",
        "\n",
        "Let's create a specialized agent for data analysis tasks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataAnalysisRequest(BaseModel):\n",
        "    \"\"\"Parameters for data analysis\"\"\"\n",
        "    data: str = Field(..., description=\"JSON string containing the data to analyze\")\n",
        "    analysis_type: str = Field(..., description=\"Type of analysis: 'statistics', 'trends', or 'visualization'\")\n",
        "    \n",
        "def analyze_data(params: Dict[str, Any]) -> str:\n",
        "    \"\"\"Mock data analysis function\"\"\"\n",
        "    try:\n",
        "        data_str = params.get(\"data\", \"[]\")\n",
        "        analysis_type = params.get(\"analysis_type\", \"statistics\")\n",
        "        \n",
        "        # Parse the data (assuming it's JSON)\n",
        "        data = json.loads(data_str)\n",
        "        \n",
        "        if analysis_type == \"statistics\":\n",
        "            # Mock statistics analysis\n",
        "            result = {\n",
        "                \"count\": len(data) if isinstance(data, list) else 1,\n",
        "                \"type\": str(type(data)),\n",
        "                \"sample\": str(data)[:100] + \"...\"\n",
        "            }\n",
        "        elif analysis_type == \"trends\":\n",
        "            # Mock trend analysis\n",
        "            result = {\n",
        "                \"trend\": \"upward\",\n",
        "                \"confidence\": 0.75,\n",
        "                \"note\": \"This is a mock trend analysis\"\n",
        "            }\n",
        "        elif analysis_type == \"visualization\":\n",
        "            # Mock visualization suggestion\n",
        "            result = {\n",
        "                \"suggested_visualization\": \"bar chart\",\n",
        "                \"alternative\": \"line graph\",\n",
        "                \"note\": \"This is a mock visualization suggestion\"\n",
        "            }\n",
        "        else:\n",
        "            result = {\"error\": \"Invalid analysis type\"}\n",
        "            \n",
        "        return json.dumps(result, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)}, indent=2)\n",
        "\n",
        "# Add this tool to our tools list\n",
        "data_analysis_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"analyze_data\",\n",
        "        \"description\": \"Analyze data for statistics, trends, or visualization suggestions\",\n",
        "        \"parameters\": DataAnalysisRequest.schema()\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create a specialized set of tools for the data analysis agent\n",
        "data_analysis_tools = [data_analysis_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_data_analysis_agent(data_query):\n",
        "    \"\"\"Run a specialized data analysis agent\"\"\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"\n",
        "            You are a specialized data analysis assistant.\n",
        "            You help users understand data, generate statistics, identify trends, \n",
        "            and suggest appropriate visualizations.\n",
        "            Always request the data in a proper format, preferably JSON.\n",
        "            Provide clear explanations of your findings.\n",
        "            \"\"\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": data_query}\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\nProcessing data query: {data_query}\")\n",
        "    \n",
        "    # Get initial response\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages,\n",
        "        tools=data_analysis_tools,\n",
        "        tool_choice=\"auto\"\n",
        "    )\n",
        "    \n",
        "    assistant_response = response.choices[0].message\n",
        "    messages.append(assistant_response)\n",
        "    \n",
        "    print(\"\\nInitial response:\")\n",
        "    if hasattr(assistant_response, 'content') and assistant_response.content:\n",
        "        print(assistant_response.content)\n",
        "    \n",
        "    # Process any tool calls\n",
        "    if assistant_response.tool_calls:\n",
        "        for tool_call in assistant_response.tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            \n",
        "            print(f\"\\nCalling {function_name}...\")\n",
        "            \n",
        "            # Execute the function\n",
        "            if function_name == \"analyze_data\":\n",
        "                function_response = analyze_data(function_args)\n",
        "            else:\n",
        "                function_response = json.dumps({\"error\": f\"Unknown function {function_name}\"})\n",
        "            \n",
        "            messages.append({\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response\n",
        "            })\n",
        "        \n",
        "        # Get final response\n",
        "        final_response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=messages\n",
        "        )\n",
        "        \n",
        "        print(\"\\nAnalysis results:\")\n",
        "        print(final_response.choices[0].message.content)\n",
        "        return final_response.choices[0].message.content\n",
        "    else:\n",
        "        return assistant_response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with some sample data\n",
        "sample_data_query = \"\"\"Can you analyze this sales data and suggest a good visualization?\n",
        "```json\n",
        "[\n",
        "  {\"month\": \"January\", \"sales\": 10000},\n",
        "  {\"month\": \"February\", \"sales\": 12000},\n",
        "  {\"month\": \"March\", \"sales\": 18000},\n",
        "  {\"month\": \"April\", \"sales\": 15000},\n",
        "  {\"month\": \"May\", \"sales\": 20000}\n",
        "]\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "data_analysis_result = run_data_analysis_agent(sample_data_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Multi-Agent Collaboration\n",
        "\n",
        "Let's demonstrate how to implement a simple multi-agent system where agents collaborate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_agent_with_persona(persona, available_tools):\n",
        "    \"\"\"Create an agent with a specific persona and toolset\"\"\"\n",
        "    \n",
        "    def agent_function(query):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": persona},\n",
        "            {\"role\": \"user\", \"content\": query}\n",
        "        ]\n",
        "        \n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            tools=available_tools,\n",
        "            tool_choice=\"auto\"\n",
        "        )\n",
        "        \n",
        "        assistant_response = response.choices[0].message\n",
        "        messages.append(assistant_response)\n",
        "        \n",
        "        # Process any tool calls\n",
        "        if assistant_response.tool_calls:\n",
        "            for tool_call in assistant_response.tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "                \n",
        "                # Map function names to functions\n",
        "                function_map = {\n",
        "                    \"search_web\": search_web,\n",
        "                    \"get_weather\": get_weather,\n",
        "                    \"analyze_text\": analyze_text,\n",
        "                    \"analyze_data\": analyze_data\n",
        "                }\n",
        "                \n",
        "                if function_name in function_map:\n",
        "                    function_response = function_map[function_name](function_args)\n",
        "                else:\n",
        "                    function_response = json.dumps({\"error\": f\"Unknown function {function_name}\"})\n",
        "                \n",
        "                messages.append({\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response\n",
        "                })\n",
        "            \n",
        "            # Get final response\n",
        "            final_response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=messages\n",
        "            )\n",
        "            \n",
        "            return final_response.choices[0].message.content\n",
        "        else:\n",
        "            return assistant_response.content\n",
        "    \n",
        "    return agent_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create specialized agents\n",
        "research_agent = create_agent_with_persona(\n",
        "    \"You are a research specialist. Your job is to find information on topics. Focus only on facts and be concise.\",\n",
        "    [tools[0]]  # Only search_web tool\n",
        ")\n",
        "\n",
        "analysis_agent = create_agent_with_persona(\n",
        "    \"You are a text analysis specialist. You analyze text for sentiment, extract entities, and create summaries.\",\n",
        "    [tools[2]]  # Only analyze_text tool\n",
        ")\n",
        "\n",
        "weather_agent = create_agent_with_persona(\n",
        "    \"You are a weather specialist. You provide detailed weather information for locations.\",\n",
        "    [tools[1]]  # Only get_weather tool\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multi_agent_workflow(query):\n",
        "    \"\"\"Run a workflow with multiple specialized agents\"\"\"\n",
        "    print(f\"\\nProcessing: {query}\")\n",
        "    \n",
        "    # First, use the main agent to decide which specialized agents to use\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"\n",
        "            You are a coordinator agent. Your job is to analyze the user query and decide which\n",
        "            specialized agents to call. You have access to these agents:\n",
        "            1. Research Agent - For finding information on topics\n",
        "            2. Analysis Agent - For analyzing text sentiment, entities, summaries\n",
        "            3. Weather Agent - For weather information\n",
        "            \n",
        "            Return your decision as a JSON object with the agents to call and sub-queries for each.\n",
        "            \"\"\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ]\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        response_format={\"type\": \"json_object\"}\n",
        "    )\n",
        "    \n",
        "    plan = json.loads(response.choices[0].message.content)\n",
        "    print(\"\\nCoordinator's plan:\")\n",
        "    print(json.dumps(plan, indent=2))\n",
        "    \n",
        "    # Execute the plan by calling each agent\n",
        "    results = {}\n",
        "    \n",
        "    if plan.get(\"research_agent\"):\n",
        "        print(\"\\nCalling Research Agent...\")\n",
        "        results[\"research\"] = research_agent(plan[\"research_agent\"])\n",
        "        \n",
        "    if plan.get(\"analysis_agent\"):\n",
        "        print(\"\\nCalling Analysis Agent...\")\n",
        "        results[\"analysis\"] = analysis_agent(plan[\"analysis_agent\"])\n",
        "        \n",
        "    if plan.get(\"weather_agent\"):\n",
        "        print(\"\\nCalling Weather Agent...\")\n",
        "        results[\"weather\"] = weather_agent(plan[\"weather_agent\"])\n",
        "    \n",
        "    # Synthesize the results\n",
        "    synthesis_prompt = f\"\"\"\n",
        "    Original query: {query}\n",
        "    \n",
        "    Results from specialized agents:\n",
        "    {json.dumps(results, indent=2)}\n",
        "    \n",
        "    Please synthesize these results into a comprehensive, well-organized response.\n",
        "    \"\"\"\n",
        "    \n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a synthesis agent. Your job is to combine results from multiple specialized agents into a coherent response.\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": synthesis_prompt}\n",
        "    ]\n",
        "    \n",
        "    final_response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages\n",
        "    )\n",
        "    \n",
        "    print(\"\\nFinal Synthesized Response:\")\n",
        "    print(final_response.choices[0].message.content)\n",
        "    \n",
        "    return {\n",
        "        \"plan\": plan,\n",
        "        \"individual_results\": results,\n",
        "        \"synthesized_response\": final_response.choices[0].message.content\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the multi-agent workflow\n",
        "complex_query = \"I'm planning a trip to Paris next week. What's the weather like there, and what are some must-see attractions? Also, can you analyze this hotel review: 'The rooms were spacious and the location was perfect, but the breakfast was disappointing.'\"\n",
        "\n",
        "workflow_results = multi_agent_workflow(complex_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook has demonstrated advanced techniques for working with OpenAI Agents:\n",
        "\n",
        "1. **Structured Tools with Pydantic** - Creating well-defined tool schemas\n",
        "2. **Advanced Multi-Tool Agents** - Agents that can use multiple tools in sequence\n",
        "3. **Specialized Agents** - Creating agents for specific tasks like data analysis\n",
        "4. **Multi-Agent Workflows** - Coordinating multiple agents to solve complex problems\n",
        "\n",
        "These patterns can be extended to build sophisticated AI applications that leverage the strengths of multiple specialized components."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
} 